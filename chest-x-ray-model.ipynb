{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[AI Lung Classification Project](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [AI Lung Classification Project](#toc1_)    \n",
    "  - [About the Project](#toc1_1_)    \n",
    "    - [Dataset Used](#toc1_1_1_)    \n",
    "  - [Managing Libraries](#toc1_2_)    \n",
    "    - [Install Libraries](#toc1_2_1_)    \n",
    "    - [Import Libraries](#toc1_2_2_)    \n",
    "  - [Pre-training Requirements](#toc1_3_)    \n",
    "    - [Importing Datasets](#toc1_3_1_)    \n",
    "    - [Calculating Steps](#toc1_3_2_)    \n",
    "  - [Implementing a DenseNet Model](#toc1_4_)    \n",
    "  - [Implementing a VGG16 Model](#toc1_5_)    \n",
    "  - [Implementing a Resnet50 Model](#toc1_6_)    \n",
    "  - [Implementing an InceptionV3 Model](#toc1_7_)    \n",
    "  - [Testing the Models](#toc1_8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[About the Project](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to develop an image classification system for chest X-Rays to differentiate between normal lungs and lungs which have pneumonia. The system uses several CNN architectures, including DenseNet121, VGG16, ResNet50, and InceptionV3. Each model is adapted for binary classification to distinguish between pneumonia-afflicted and healthy lung images. \n",
    "To prevent overfitting and ensure the best model performance, early stopping and model checkpoints are implemented. These methods monitor validation loss across epochs, halting training when no improvement is seen and saving the best model respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Dataset Used](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia/Normal).\n",
    "\n",
    "Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children’s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients’ routine clinical care.\n",
    "\n",
    "For the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\"\n",
    "\n",
    "The dataset can be found here - https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "**Acknowledgements**\n",
    "\n",
    "Data: https://data.mendeley.com/datasets/rscbjbr9sj/2\n",
    "\n",
    "License: CC BY 4.0\n",
    "\n",
    "Citation: http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Managing Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Install Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Import Libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T16:05:07.086363Z",
     "iopub.status.busy": "2024-04-02T16:05:07.086028Z",
     "iopub.status.idle": "2024-04-02T16:05:24.068099Z",
     "shell.execute_reply": "2024-04-02T16:05:24.067192Z",
     "shell.execute_reply.started": "2024-04-02T16:05:07.086338Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.applications import ResNet50\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Pre-training Requirements](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Importing Datasets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T02:17:43.948995Z",
     "iopub.status.busy": "2024-04-02T02:17:43.948175Z",
     "iopub.status.idle": "2024-04-02T02:17:43.953516Z",
     "shell.execute_reply": "2024-04-02T02:17:43.952226Z",
     "shell.execute_reply.started": "2024-04-02T02:17:43.948964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "train_dir = 'datasets/train'\n",
    "validation_dir = 'datasets/val'\n",
    "test_dir = 'datasets/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Calculating Steps](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T02:17:46.631721Z",
     "iopub.status.busy": "2024-04-02T02:17:46.631052Z",
     "iopub.status.idle": "2024-04-02T02:17:50.242879Z",
     "shell.execute_reply": "2024-04-02T02:17:50.241848Z",
     "shell.execute_reply.started": "2024-04-02T02:17:46.631684Z"
    }
   },
   "outputs": [],
   "source": [
    "# Counts number of images to be used later in calculating steps\n",
    "def count_files(directory):\n",
    "    return sum(len(files) for _, _, files in os.walk(directory))\n",
    "\n",
    "train_images = count_files(train_dir)\n",
    "val_images = count_files(validation_dir)\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Implementing a DenseNet Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T02:17:56.322345Z",
     "iopub.status.busy": "2024-04-02T02:17:56.321524Z",
     "iopub.status.idle": "2024-04-02T02:28:21.054644Z",
     "shell.execute_reply": "2024-04-02T02:28:21.053610Z",
     "shell.execute_reply.started": "2024-04-02T02:17:56.322316Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_densenet_datagen(directory):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return datagen.flow_from_directory(directory, target_size=(224, 224), batch_size=20, class_mode='binary')\n",
    "\n",
    "train_generator = create_densenet_datagen(train_dir)\n",
    "validation_generator = create_densenet_datagen(validation_dir)\n",
    "test_generator = create_densenet_datagen(test_dir)\n",
    "\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_densenet = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model_densenet.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping\n",
    "\n",
    "early_stopping_dn = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Saves checkpoint file\n",
    "\n",
    "model_checkpoint_dn = ModelCheckpoint(\n",
    "    filepath='lung_classifier_dn.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "\n",
    "history_densenet = model_densenet.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_images // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_images // batch_size,\n",
    "    callbacks=[early_stopping_dn, model_checkpoint_dn]\n",
    ")\n",
    "\n",
    "# Save model training history\n",
    "\n",
    "with open('model_densenet_history.json', 'w') as f:\n",
    "    json.dump(history_densenet.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Implementing a VGG16 Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T02:29:36.003498Z",
     "iopub.status.busy": "2024-04-02T02:29:36.003102Z",
     "iopub.status.idle": "2024-04-02T02:38:48.613311Z",
     "shell.execute_reply": "2024-04-02T02:38:48.612404Z",
     "shell.execute_reply.started": "2024-04-02T02:29:36.003469Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_generator(directory):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return datagen.flow_from_directory(directory, target_size=(224, 224), batch_size=20, class_mode='binary')\n",
    "\n",
    "train_generator = create_data_generator(train_dir)\n",
    "validation_generator = create_data_generator(validation_dir)\n",
    "test_generator = create_data_generator(test_dir)\n",
    "\n",
    "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in vgg16_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = vgg16_base.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x) \n",
    "predictions_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "vgg16_model = Model(inputs=vgg16_base.input, outputs=predictions_layer)\n",
    "vgg16_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping_vgg = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint_vgg = ModelCheckpoint(\n",
    "    filepath='lung_classifier_vgg.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_vgg16 = vgg16_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_images // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_images // batch_size,\n",
    "    callbacks=[early_stopping_vgg, model_checkpoint_vgg]\n",
    ")\n",
    "\n",
    "with open('model_vgg16_history.json', 'w') as f:\n",
    "    json.dump(history_densenet.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Implementing a Resnet50 Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T02:39:33.735297Z",
     "iopub.status.busy": "2024-04-02T02:39:33.734394Z",
     "iopub.status.idle": "2024-04-02T02:45:36.884587Z",
     "shell.execute_reply": "2024-04-02T02:45:36.883605Z",
     "shell.execute_reply.started": "2024-04-02T02:39:33.735263Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_generator(directory):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return datagen.flow_from_directory(directory, target_size=(224, 224), batch_size=20, class_mode='binary')\n",
    "\n",
    "train_generator = create_data_generator(train_dir)\n",
    "validation_generator = create_data_generator(validation_dir)\n",
    "test_generator = create_data_generator(test_dir)\n",
    "\n",
    "resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in resnet50_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = resnet50_base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "resnet50_model = Model(inputs=resnet50_base.input, outputs=predictions_layer)\n",
    "resnet50_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping_resnet = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint_resnet = ModelCheckpoint(\n",
    "    filepath='lung_classifier_rn.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_resnet50 = resnet50_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_images // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_images // batch_size,\n",
    "    callbacks=[early_stopping_resnet, model_checkpoint_resnet]\n",
    ")\n",
    "\n",
    "with open('model_resnet_history.json', 'w') as f:\n",
    "    json.dump(history_densenet.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Implementing an InceptionV3 Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T02:46:54.841265Z",
     "iopub.status.busy": "2024-04-02T02:46:54.840866Z",
     "iopub.status.idle": "2024-04-02T02:54:11.126379Z",
     "shell.execute_reply": "2024-04-02T02:54:11.125399Z",
     "shell.execute_reply.started": "2024-04-02T02:46:54.841233Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_generator(directory):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    return datagen.flow_from_directory(directory, target_size=(299, 299), batch_size=20, class_mode='binary')\n",
    "\n",
    "train_generator = create_data_generator(train_dir)\n",
    "validation_generator = create_data_generator(validation_dir)\n",
    "test_generator = create_data_generator(test_dir)\n",
    "\n",
    "inceptionv3_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "for layer in inceptionv3_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = inceptionv3_base.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "inceptionv3_model = Model(inputs=inceptionv3_base.input, outputs=predictions_layer)\n",
    "inceptionv3_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping_inception = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint_inception = ModelCheckpoint(\n",
    "    filepath='lung_classifier_inceptionv3.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_inceptionv3 = inceptionv3_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_images // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_images // batch_size,\n",
    "    callbacks=[early_stopping_inception, model_checkpoint_inception]\n",
    ")\n",
    "\n",
    "with open('model_inceptionv3_history.json', 'w') as f:\n",
    "    json.dump(history_inceptionv3.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[Testing the Models](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-02T02:54:37.461348Z",
     "iopub.status.busy": "2024-04-02T02:54:37.460973Z",
     "iopub.status.idle": "2024-04-02T02:56:07.376180Z",
     "shell.execute_reply": "2024-04-02T02:56:07.375209Z",
     "shell.execute_reply.started": "2024-04-02T02:54:37.461321Z"
    }
   },
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    'ResNet50': 'lung_classifier_rn.keras',\n",
    "    'VGG16': 'lung_classifier_vgg.keras',\n",
    "    'DenseNet': 'lung_classifier_dn.keras',\n",
    "    'InceptionV3': 'lung_classifier_inceptionv3.keras'\n",
    "}\n",
    "\n",
    "for model_name, model_path in model_paths.items():\n",
    "    if model_name == 'InceptionV3':\n",
    "        target_size = (299, 299)\n",
    "    else:\n",
    "        target_size = (224, 224)\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=20,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    \n",
    "    print(f\"{model_name} Test Loss: {loss:.4f}\")\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
